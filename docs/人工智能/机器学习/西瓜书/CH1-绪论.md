# 第一章 绪论

傍晚小街路面上沁出微雨后的湿润，和熙的细风吹来，抬头看看天边的晚霞，嗯，明天又是一个好天气。走到水果摊旁，挑了个根蒂蜷缩、敲起来声音浊响的青绿西瓜，一边满心期待着皮薄肉厚瓢甜的爽落感，一边愉快地想着，这学期狠下了工夫，基础概念弄得清清楚楚，算法作业也是信手拈来，这门课成绩一定差不了！哈哈，也希望自己这学期的 Machine Learning 课程取得一个好成绩！

## 1.1 引言

![image-20200609152836836](https://gitee.com/wugenqiang/PictureBed/raw/master/NoteBook/20200609152838.png)

### ① 机器学习的定义

正如我们根据过去的经验来判断明天的天气，吃货们希望从购买经验中挑选一个好瓜，那能不能让计算机帮助人类来实现这个呢？机器学习正是这样的一门学科，人的“经验”对应计算机中的“数据”，让计算机来学习这些经验数据，生成一个算法模型，在面对新的情况中，计算机便能作出有效的判断，这便是机器学习。

另一本经典教材的作者 Mitchell 给出了一个形式化的定义，假设：

- P：计算机程序在某任务类 T 上的性能。
- T：计算机程序希望实现的任务类。
- E：表示经验，即历史的数据集。

若该计算机程序通过利用经验 E 在任务 T 上获得了性能 P 的改善，则称该程序对 E 进行了学习。

**总结归纳**

机器学习（Machine Learning）致力于研究如何通过计算的手段，利用经验来改善系统自身的性能，从而在计算机上从数据中产生“模型”，用于对新的情况给出判断。

在计算机系统中，“经验”通常以“数据”的形式存在。

ML 研究的主要内容：在计算机上、从数据中产生“模型 model ”的算法。即是：如何通过数据集产生模型？因此机器学习本质上，研究的是算法；而这种算法的作用是，从数据集中产生模型；而模型的作用是，当面对新的数据时，模型会给我们提供一定的判断，即是数据预测。

模型，可以看做是：从数据集中学得的结果。

机器学习，是研究**算法**的学问。

## 1.2 基本术语

![image-20200609162159805](https://gitee.com/wugenqiang/PictureBed/raw/master/NoteBook/20200609162200.png)

假设我们收集了一批西瓜的数据，例如：（色泽=青绿;根蒂=蜷缩;敲声=浊响)， (色泽=乌黑;根蒂=稍蜷;敲声=沉闷)， (色泽=浅自;根蒂=硬挺;敲声=清脆)……每对括号内是一个西瓜的记录，定义：

- 所有记录的集合为：数据集。
- 每一条记录为：一个示例（instance）或样本（sample）。
- 例如：色泽或敲声，单个的特点为特征（feature）或属性（attribute）。
- 对于一条记录，如果在坐标轴上表示，每个西瓜都可以用坐标轴中的一个点表示，一个点也是一个向量，例如（青绿，蜷缩，浊响），即每个西瓜为：一个特征向量（feature vector）。
- 一个样本的特征数为：维数（dimensionality），该西瓜的例子维数为3，当维数非常大时，也就是现在说的“维数灾难”。

计算机程序学习经验数据生成算法模型的过程中，每一条记录称为一个“训练样本”，同时在训练好模型后，我们希望使用新的样本来测试模型的效果，则每一个新的样本称为一个“测试样本”。定义：

- 所有训练样本的集合为：训练集（trainning set），[特殊]。
- 所有测试样本的集合为：测试集（test set），[一般]。
- 机器学习出来的模型适用于新样本的能力为：泛化能力（generalization），即从特殊到一般。

![image-20200609162342909](https://gitee.com/wugenqiang/PictureBed/raw/master/NoteBook/20200609162404.png)

西瓜的例子中，我们是想计算机通过学习西瓜的特征数据，训练出一个决策模型，来判断一个新的西瓜是否是好瓜。可以得知我们预测的是：西瓜是好是坏，即好瓜与差瓜两种，是离散值。同样地，也有通过历年的人口数据，来预测未来的人口数量，人口数量则是连续值。定义：

- 预测值为离散值的问题为：分类（classification）。
- 预测值为连续值的问题为：回归（regression）。

![image-20200609162519955](https://gitee.com/wugenqiang/PictureBed/raw/master/NoteBook/20200609162521.png)

我们预测西瓜是否是好瓜的过程中，很明显对于训练集中的西瓜，我们事先已经知道了该瓜是否是好瓜，学习器通过学习这些好瓜或差瓜的特征，从而总结出规律，即训练集中的西瓜我们都做了标记，称为标记信息。但也有没有标记信息的情形，例如：我们想将一堆西瓜根据特征分成两个小堆，使得某一堆的西瓜尽可能相似，即都是好瓜或差瓜，对于这种问题，我们事先并不知道西瓜的好坏，样本没有标记信息。定义：

- 训练数据有标记信息的学习任务为：监督学习（supervised learning），容易知道上面所描述的分类和回归都是监督学习的范畴。
- 训练数据没有标记信息的学习任务为：无监督学习（unsupervised learning），常见的有聚类和关联规则。



## 1.3 假设空间

![image-20200609164215367](https://gitee.com/wugenqiang/PictureBed/raw/master/NoteBook/20200609164216.png)

假设空间：即所有假设组成的空间

归纳和演绎是科学推理的两大基本手段：

* 归纳——泛化过程
* 演绎——特化过程

样本有3个属性，每个属性有3种可能取值，则假设空间规模大小为4×4×4+1=65，每个属性多出一种无论这个属性取什么值都满足的情况“*”，用空值表示分类的种类不存在的情况，比如无论属性是什么，瓜始终都是好瓜，不存在孬瓜（+1），代表空集。

![image-20200609165356778](https://gitee.com/wugenqiang/PictureBed/raw/master/NoteBook/20200609165357.png)

## 1.4 归纳偏好

![image-20200609165943594](https://gitee.com/wugenqiang/PictureBed/raw/master/NoteBook/20200609165944.png)

学习过程中对某种类型假设的偏好称作归纳偏好。

![image-20200609170643510](https://gitee.com/wugenqiang/PictureBed/raw/master/NoteBook/20200609170644.png)

归纳偏好可看作学习算法自身在一个可能很庞大的假设空间中对假设进行选择的启发式或“价值观”。

“奥卡姆剃刀”是一种常用的、自然科学研究中最基本的原则，即“若有多个假设与观察一致，选最简单的那个”。

具体的现实问题中，学习算法本身所做的假设是否成立，也即算法的归纳偏好是否与问题本身匹配，大多数时候直接决定了算法能否取得好的性能。




